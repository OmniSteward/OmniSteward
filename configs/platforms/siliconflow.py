api_base = "https://api.siliconflow.cn/v1"
models = [
    "Qwen/Qwen2.5-7B-Instruct",
    "Qwen/Qwen2.5-14B-Instruct",
    "Qwen/Qwen2.5-32B-Instruct",
    "Qwen/Qwen2.5-72B-Instruct",
    "Qwen/Qwen2.5-72B-Instruct-128K",
    "AIDC-AI/Marco-o1",
    "Qwen/QwQ-32B-Preview",
    "01-ai/Yi-1.5-34B-Chat-16K",
    "01-ai/Yi-1.5-6B-Chat",
    "01-ai/Yi-1.5-9B-Chat-16K",
    "Qwen/Qwen2.5-Coder-32B-Instruct",
    "Qwen/Qwen2.5-Coder-7B-Instruct",
    "OpenGVLab/InternVL2-26B",
    "OpenGVLab/InternVL2-Llama3-76B",
    "Qwen/Qwen2-1.5B-Instruct",
    "Qwen/Qwen2-72B-Instruct",
    "Qwen/Qwen2-7B-Instruct",
    "Qwen/Qwen2-VL-72B-Instruct",
    "THUDM/chatglm3-6b",
    "THUDM/glm-4-9b-chat",
    "TeleAI/TeleChat2",
    "TeleAI/TeleMM",
    "deepseek-ai/DeepSeek-V2-Chat",
    "deepseek-ai/DeepSeek-V2.5",
    "deepseek-ai/deepseek-vl2",
    "google/gemma-2-27b-it",
    "google/gemma-2-9b-it",
    "internlm/internlm2_5-20b-chat",
    "internlm/internlm2_5-7b-chat",
    "meta-llama/Llama-3.3-70B-Instruct",
    "meta-llama/Meta-Llama-3.1-405B-Instruct",
    "meta-llama/Meta-Llama-3.1-70B-Instruct",
    "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "LoRA/Qwen/Qwen2.5-14B-Instruct",
    "LoRA/Qwen/Qwen2.5-32B-Instruct",
    "LoRA/Qwen/Qwen2.5-72B-Instruct",
    "LoRA/Qwen/Qwen2.5-7B-Instruct",
    "Pro/OpenGVLab/InternVL2-8B",
    "Pro/Qwen/Qwen2-1.5B-Instruct",
    "Pro/Qwen/Qwen2-7B-Instruct",
    "Pro/Qwen/Qwen2-VL-7B-Instruct",
    "Pro/Qwen/Qwen2.5-7B-Instruct",
    "Pro/Qwen/Qwen2.5-Coder-7B-Instruct",
    "Pro/THUDM/glm-4-9b-chat",
    "Pro/google/gemma-2-9b-it",
    "Pro/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "Vendor-A/Qwen/Qwen2-72B-Instruct",
    "Vendor-A/Qwen/Qwen2.5-72B-Instruct",
]
